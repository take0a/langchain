# Tools

:::info Prerequisites
- [Chat models](/docs/concepts/chat_models/)
:::

## 概要

LangChain の **tool** 抽象化は、Python **関数** を、関数の **名前**、**説明**、および **想定される引数** を定義する **スキーマ** に関連付けます。

**Tools** は、[ツール呼び出し](/docs/concepts/tool_calling) をサポートする [チャットモデル](/docs/concepts/chat_models) に渡すことができ、モデルは特定の入力値で特定の関数の実行を要求できます。

## 主要な概念

- ツールは、関数とそのスキーマをカプセル化し、チャットモデルに渡すことができる方法です。
- [@tool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html) デコレータを使用してツールを作成します。これにより、ツール作成プロセスが簡素化され、以下の機能がサポートされます。
    - ツールの **名前**、**説明**、**想定される引数** を自動的に推測し、カスタマイズもサポートします。
    - **成果物** (画像、データフレームなど) を返すツールを定義します。
    - **挿入されたツール引数** を使用して、入力引数をスキーマ (およびモデル) から隠蔽します。

## ツールインターフェース

ツールインターフェースは、[Runnable インターフェース](/docs/concepts/runnables) のサブクラスである [BaseTool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.BaseTool.html#langchain_core.tools.base.BaseTool) クラスで定義されています。

ツールの **schema** に対応する主要な属性は次のとおりです。

- **name**: ツールの名前。
- **description**: ツールの機能の説明。
- **args**: ツールの引数の JSON スキーマを返すプロパティ。

**tool** に関連付けられた関数を実行するための主要なメソッドは次のとおりです。

- **invoke**: 指定された引数でツールを呼び出します。
- **ainvoke**: 指定された引数でツールを非同期的に呼び出します。 [Langchain を使用した非同期プログラミング](/docs/concepts/async)に使用されます。

## `@tool` デコレータを使用してツールを作成する

ツールを作成する場合は、[@tool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html) デコレータを使用することをお勧めします。このデコレータはツール作成プロセスを簡素化するように設計されており、ほとんどの場合に使用できます。関数を定義した後、[@tool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html) でデコレートすることで、[ツールインターフェース](#tool-interface) を実装したツールを作成できます。

```python
from langchain_core.tools import tool

@tool
def multiply(a: int, b: int) -> int:
   """Multiply two numbers."""
   return a * b
```

ツールの作成方法の詳細については、[カスタム ツールを作成する方法](/docs/how_to/custom_tools/) ガイドを参照してください。

:::note
LangChainには、ツールを作成する方法が他にもいくつかあります。例えば、[BaseTool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.BaseTool.html#langchain_core.tools.base.BaseTool) クラスのサブクラス化や、`StructuredTool` を使用する方法などがあります。これらの方法は[カスタムツールの作成方法ガイド](/docs/how_to/custom_tools/)に記載されていますが、ほとんどの場合、`@tool` デコレータを使用することをお勧めします。
:::

## ツールを直接使用する

ツールを定義したら、関数を呼び出すことで直接使用できます。例えば、上記で定義した「multiply」ツールを使用するには、次のようにします。

```python
multiply.invoke({"a": 2, "b": 3})
```

### 検査

ツールのスキーマやその他のプロパティを検査することもできます。

```python
print(multiply.name) # multiply
print(multiply.description) # Multiply two numbers.
print(multiply.args) 
# {
# 'type': 'object', 
# 'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 
# 'required': ['a', 'b']
# }
```

:::note
[create_react_agent](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)のような、LangChainまたはLangGraphのビルド済みコンポーネントを使用している場合は、ツールを直接操作する必要がないかもしれません。しかし、それらの使い方を理解しておくことは、デバッグやテストを行う上で役立ちます。また、カスタムLangGraphワークフローを構築する際には、ツールを直接操作する必要がある場合もあります。
:::

## スキーマの設定

`@tool` デコレータは、ツールのスキーマを設定するための追加オプションを提供します（例：名前や説明の変更、関数の doc-string を解析してスキーマを推測するなど）。

詳細については、[@tool の API リファレンス](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html) を参照してください。また、例については、[カスタムツールの作成方法](/docs/how_to/custom_tools/) ガイドをご覧ください。

## ツールアーティファクト

**ツール** は、モデルから呼び出すことができるユーティリティであり、その出力はモデルにフィードバックされるように設計されています。しかし、ツール実行のアーティファクトの中には、チェーンやエージェント内の下流コンポーネントからアクセスできるようにしたいものの、モデル自体には公開したくないものがあります。例えば、ツールがカスタムオブジェクト、データフレーム、または画像を返す場合、実際の出力をモデルに渡さずに、その出力に関するメタデータをモデルに渡したい場合があります。同時に、下流ツールなど、他の場所からこの出力全体にアクセスできるようにしたい場合もあります。

```python
@tool(response_format="content_and_artifact")
def some_tool(...) -> Tuple[str, Any]:
    """Tool that does something."""
    ...
    return 'Message for chat model', some_artifact 
```

詳細については、[ツールから成果物を返す方法](/docs/how_to/tool_artifacts/)を参照してください。

## 特殊な型アノテーション

ツールの関数シグネチャ内で使用して、ツールの実行時の動作を設定できる特殊な型アノテーションがいくつかあります。

以下の型アノテーションは、ツールのスキーマから引数を**削除**します。これは、モデルに公開すべきではない引数や、モデルが制御できない引数に便利です。

- **InjectedToolArg**: 実行時に `.invoke` または `.ainvoke` を使用して手動で値を注入する必要があります。
- **RunnableConfig**: RunnableConfig オブジェクトをツールに渡します。
- **InjectedState**: LangGraph グラフの全体的な状態をツールに渡します。
- **InjectedStore**: LangGraph ストアオブジェクトをツールに渡します。

`Annotated` 型を文字列リテラルと共に使用することで、ツールのスキーマで公開される対応する引数の **説明** を指定することもできます。

- **Annotated[..., "文字列リテラル"]** -- ツールのスキーマで公開される引数に説明を追加します。

### InjectedToolArg

実行時にツールに渡す必要がある引数があるものの、モデル自体では生成したくない場合があります。このような場合には、`InjectedToolArg` アノテーションを使用します。これにより、特定のパラメータをツールのスキーマから隠蔽できます。

例えば、ツールが実行時に動的に `user_id` を注入する必要がある場合、次のように構造化できます。

```python
from langchain_core.tools import tool, InjectedToolArg

@tool
def user_specific_tool(input_data: str, user_id: InjectedToolArg) -> str:
    """Tool that processes input data."""
    return f"User {user_id} processed {input_data}"
```

`user_id` 引数に `InjectedToolArg` アノテーションを付けることにより、LangChain に対して、この引数をツールのスキーマの一部として公開しないことを指示します。

`InjectedToolArg` の使用方法の詳細については、[実行時の値をツールに渡す方法](/docs/how_to/tool_runtime/) を参照してください。


### RunnableConfig

`RunnableConfig` オブジェクトを使用すると、ツールにカスタム実行時値を渡すことができます。

ツール内から [RunnableConfig](/docs/concepts/runnables/#runnableconfig) オブジェクトにアクセスする必要がある場合は、ツールの関数シグネチャで `RunnableConfig` アノテーションを使用することで実現できます。

```python
from langchain_core.runnables import RunnableConfig

@tool
async def some_func(..., config: RunnableConfig) -> ...:
    """Tool that does something."""
    # do something with config
    ...

await some_func.ainvoke(..., config={"configurable": {"value": "some_value"}})
```

`config` はツールのスキーマの一部ではなく、実行時に適切な値が挿入されます。

:::note
`config` オブジェクトにアクセスして、サブクラスに手動で伝播させる必要がある場合があります。これは、Python 3.9 / 3.10 を [async](/docs/concepts/async) 環境で使用していて、`config` オブジェクトをサブクラス呼び出しに手動で伝播させる必要がある場合に発生します。

`RunnableConfig を呼び出しチェーンに手動で伝播させる方法については、[RunnableConfig の伝播](/docs/concepts/runnables/#propagation-of-runnableconfig) を参照してください（または、この問題が解消される Python 3.11 にアップグレードしてください）。
:::

### InjectedState

詳細については、[InjectedState](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.InjectedState) のドキュメントを参照してください。

### InjectedStore

詳細については、[InjectedStore](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.InjectedStore) のドキュメントを参照してください。

## ベストプラクティス

モデルで使用するツールを設計する際は、以下の点に留意してください。

- 適切な名前が付けられ、正しくドキュメント化され、適切な型ヒントが設定されたツールは、モデルにとって使いやすくなります。
- シンプルでスコープを限定したツールを設計すると、モデルにとって正しく使いやすくなります。
- ツールを活用するには、[ツール呼び出し](/docs/concepts/tool_calling) API をサポートするチャットモデルを使用してください。


## Toolkits
<span data-heading-keywords="toolkit,toolkits"></span>

LangChainには**toolkits**という概念があります。これは、特定のタスクで一緒に使用するように設計されたツールをグループ化した、非常に薄い抽象化です。

### Interface

すべてのツールキットはツールのリストを返す `get_tools` メソッドを公開しています。そのため、次のように実行できます。

```python
# Initialize a toolkit
toolkit = ExampleToolkit(...)

# Get list of tools
tools = toolkit.get_tools()
```

## 関連リソース

詳細については、以下のリソースをご覧ください。

- [@tool の API リファレンス](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html)
- [カスタムツールの作成方法](/docs/how_to/custom_tools/)
- [ツールにランタイム値を渡す方法](/docs/how_to/tool_runtime/)
- [LangChain ツールのすべてのハウツーガイド](https://docs.langchain.com/docs/how_to/#tools)
- [LangGraph の使用方法を示す追加のハウツーガイド](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/)
- ツールの統合については、[ツール統合ドキュメント](https://docs.langchain.com/docs/integrations/tools/)をご覧ください。

