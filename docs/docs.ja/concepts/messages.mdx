# Messages

:::info Prerequisites
- [Chat Models](/docs/concepts/chat_models)
:::

## 概要

メッセージは、[チャットモデル](/docs/concepts/chat_models)におけるコミュニケーションの単位です。メッセージは、チャットモデルの入出力、および会話に関連付けられる追加のコンテキストやメタデータを表すために使用されます。

各メッセージには**役割**（例：ユーザー、アシスタント）と**コンテンツ**（例：テキスト、マルチモーダルデータ）があり、追加のメタデータはチャットモデルプロバイダーによって異なります。

LangChainは、複数のチャットモデルで使用できる統一されたメッセージ形式を提供します。これにより、ユーザーは各モデルプロバイダーが使用するメッセージ形式の詳細を気にすることなく、異なるチャットモデルを操作できます。

## メッセージの内容

メッセージは通常、以下の情報で構成されます。

- **Role**: メッセージの役割（例：「ユーザー」、「アシスタント」）。
- **Content**: メッセージの内容（例：テキスト、マルチモーダルデータ）。
- 追加のメタデータ：ID、名前、[トークンの使用状況](/docs/concepts/tokens)、およびその他のモデル固有のメタデータ。

### Role

ロールは、会話内の異なるタイプのメッセージを区別するために使用され、チャット モデルが特定のメッセージ シーケンスにどのように応答するかを理解するのに役立ちます。

| **Role**              | **Description**                                                                                                                                                                                                 |
|-----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **system**            | チャットモデルの動作を指示し、追加のコンテキストを提供するために使用されます。すべてのチャットモデルプロバイダーでサポートされているわけではありません。|
| **user**              | 通常はテキストまたはその他の対話型入力の形式で、モデルと対話するユーザーからの入力を表します。|
| **assistant**         | モデルからの応答を表します。これには、テキストやツールを呼び出す要求が含まれます。|
| **tool**              | 外部データまたは処理を取得した後、ツール呼び出しの結果をモデルに返すために使用されるメッセージです。[ツール呼び出し](/docs/concepts/tool_calling)をサポートするチャットモデルで使用されます。|
| **function** (legacy) | これは、OpenAI のレガシー関数呼び出し API に対応するレガシー ロールです。代わりに **tool** ロールを使用する必要があります。|

### Content

メッセージテキストの内容、または[マルチモーダルデータ](/docs/concepts/multimodality)（画像、音声、動画など）を表す辞書のリスト。コンテンツの正確な形式は、チャットモデルプロバイダーによって異なります。

現在、ほとんどのチャットモデルは主要なコンテンツタイプとしてテキストをサポートしており、一部のモデルはマルチモーダルデータもサポートしています。ただし、ほとんどのチャットモデルプロバイダーでは、マルチモーダルデータのサポートは依然として限定的です。

詳細については、以下を参照してください。
* [SystemMessage](#systemmessage) -- 会話を方向付けるために渡すコンテンツ
* [HumanMessage](#humanmessage) -- ユーザーからの入力に含まれるコンテンツ
* [AIMessage](#aimessage) -- モデルからの応答に含まれるコンテンツ
* [Multimodality](/docs/concepts/multimodality) -- マルチモーダルコンテンツの詳細については、以下を参照してください。

### その他のメッセージデータ

チャットモデルプロバイダーによっては、メッセージに以下のようなデータが含まれる場合があります。

- **ID**: メッセージの一意の識別子（オプション）。
- **Name**: 同じ役割を持つ異なるエンティティ/スピーカーを区別するための、オプションの `name` プロパティ。すべてのモデルでサポートされているわけではありません。
- **Metadata**: タイムスタンプ、トークンの使用状況など、メッセージに関する追加情報。
- **Tool Calls**: モデルが1つ以上のツールを呼び出すためのリクエスト。詳細については、[ツール呼び出し](/docs/concepts/tool_calling) を参照してください。

## 会話構造

チャットモデルへのメッセージの順序は、チャットモデルが有効な応答を生成できるように、特定の構造に従う必要があります。

例えば、典型的な会話構造は次のようになります。

1. **ユーザーメッセージ**: 「こんにちは、お元気ですか？」
2. **アシスタントメッセージ**: 「元気です。ありがとうございます。」
3. **ユーザーメッセージ**: 「ジョークを言ってもらえますか？」
4. **アシスタントメッセージ**: 「もちろんです！かかしがなぜ賞を受賞したのですか？ それは、彼がその分野で傑出していたからです！」

チャット履歴の管理と会話構造の正確性を確認する方法の詳細については、[チャット履歴](/docs/concepts/chat_history)ガイドをご覧ください。

## LangChain メッセージ

LangChain は、すべてのチャットモデルで使用できる統一されたメッセージ形式を提供します。これにより、ユーザーは各モデルプロバイダーが使用するメッセージ形式の詳細を気にすることなく、さまざまなチャットモデルを操作できます。

LangChain メッセージは、[BaseMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.base.BaseMessage.html) のサブクラスである Python オブジェクトです。

主なメッセージタイプは5つあります。

- [SystemMessage](#systemmessage): **system** ロールに対応します。
- [HumanMessage](#humanmessage): **user** ロールに対応します。
- [AIMessage](#aimessage): **assistant** ロールに対応します。
- [AIMessageChunk](#aimessagechunk): **assistant** ロールに対応し、[streaming](/docs/concepts/streaming) レスポンスに使用されます。
- [ToolMessage](#toolmessage): **tool** ロールに対応します。

その他の重要なメッセージは次のとおりです。

- [RemoveMessage](#removemessage) -- どのロールにも対応しません。これは抽象化であり、主に [LangGraph](/docs/concepts/architecture#langgraph) でチャット履歴を管理するために使用されます。
- **Legacy** [FunctionMessage](#legacy-functionmessage): OpenAI の **legacy** 関数呼び出し API の **function** ロールに対応します。

**メッセージ** の詳細については、[API リファレンス](https://python.langchain.com/api_reference/core/messages.html) を参照してください。

### SystemMessage

`SystemMessage` は、AI モデルの動作を準備し、特定のペルソナを採用するようモデルに指示したり、会話のトーンを設定したりするなど、追加のコンテキストを提供するために使用されます（例: 「これは料理に関する会話です」）。

チャットプロバイダーによって、システムメッセージのサポート方法は異なります。

* **「システム」メッセージロール経由**：この場合、システムメッセージはメッセージシーケンスの一部として含まれ、ロールは明示的に「システム」に設定されます。
* **システム指示用の個別の API パラメータ経由**：システム指示はメッセージとして含まれるのではなく、専用の API パラメータを介して渡されます。
* **システムメッセージはサポートされていません**：一部のモデルでは、システムメッセージが全くサポートされていません。

主要なチャットモデルプロバイダーのほとんどは、チャットメッセージまたは個別の API パラメータを介してシステム指示をサポートしています。LangChain はプロバイダーの機能に応じて自動的に適応します。プロバイダーがシステム指示用の個別の API パラメータをサポートしている場合、LangChain はシステムメッセージの内容を抽出し、そのパラメータを介して渡します。

プロバイダーがシステムメッセージをサポートしていない場合、ほとんどの場合、LangChainはシステムメッセージの内容をHumanMessageに組み込もうと試みるか、それが不可能な場合は例外を発生させます。ただし、この動作はまだすべての実装で一貫して適用されているわけではありません。あまり一般的ではないチャットモデルの実装（例えば、`langchain-community`パッケージの実装）を使用する場合は、そのモデルの特定のドキュメントを確認することをお勧めします。

### HumanMessage

`HumanMessage` は **「ユーザー」** ロールに対応します。ヒューマンメッセージは、モデルと対話するユーザーからの入力を表します。

#### テキストコンテンツ

ほとんどのチャット モデルでは、ユーザー入力がテキスト形式であることが想定されています。

```python
from langchain_core.messages import HumanMessage

model.invoke([HumanMessage(content="Hello, how are you?")])
```

:::tip
文字列を入力としてチャットモデルを呼び出すと、LangChainは自動的にその文字列を`HumanMessage`オブジェクトに変換します。これは主に簡単なテストに役立ちます。

```python
model.invoke("Hello, how are you?")
```
:::

#### マルチモーダルコンテンツ

一部のチャットモデルは、画像、音声、動画、PDFなどのファイルなど、マルチモーダルな入力を受け付けます。

詳しくは、[マルチモーダル](/docs/concepts/multimodality)ガイドをご覧ください。

### AIMessage

`AIMessage` は、**"assistant"** の役割を持つメッセージを表すために使用されます。これはモデルからの応答であり、テキストやツールの呼び出しリクエストを含めることができます。また、画像、音声、動画といった他のメディアタイプを含めることもできますが、現時点ではまだ一般的ではありません。

```python
from langchain_core.messages import HumanMessage
ai_message = model.invoke([HumanMessage("Tell me a joke")])
ai_message # <-- AIMessage
```

`AIMessage` には以下の属性があります。**標準化** された属性は、LangChain がさまざまなチャットモデルプロバイダー間で標準化しようとしている属性です。**raw** フィールドはモデルプロバイダーに固有であり、異なる場合があります。

| Attribute            | Standardized/Raw | Description                                                                                                                                                                                                             |
|----------------------|:-----------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `content`            | Raw              | 通常は文字列ですが、コンテンツブロックのリストを指定することもできます。詳細は[content](#content)を参照してください。|
| `tool_calls`         | Standardized     | メッセージに関連付けられたツール呼び出し。詳細については[ツール呼び出し](/docs/concepts/tool_calling)をご覧ください。|
| `invalid_tool_calls` | Standardized     | メッセージに関連する解析エラーのあるツール呼び出し。詳細は[ツール呼び出し](/docs/concepts/tool_calling)をご覧ください。 |
| `usage_metadata`     | Standardized     | メッセージの使用状況メタデータ（[トークン数](/docs/concepts/tokens)など）。[使用状況メタデータAPIリファレンス](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.UsageMetadata.html)を参照してください。|
| `id`                 | Standardized     | メッセージのオプションの一意の識別子。理想的には、メッセージを作成したプロバイダー/モデルによって提供されます。 |
| `response_metadata`  | Raw              | 応答メタデータ (応答ヘッダー、logprob、トークン数など)。|

#### コンテンツ

`AIMessage` の **content** プロパティは、チャットモデルによって生成されたレスポンスを表します。

コンテンツは次のいずれかです。

- **text** -- ほぼすべてのチャットモデルで標準です。
- **辞書のリスト** -- 各辞書はコンテンツブロックを表し、`type` に関連付けられています。
    * Anthropic が [ツール呼び出し](/docs/concepts/tool_calling) を行う際にエージェントの思考プロセスを表面化させるために使用されます。
    * OpenAI が音声出力に使用します。詳細については、[マルチモーダルコンテンツ](/docs/concepts/multimodality) を参照してください。

:::important
**content** プロパティは、さまざまなチャットモデルプロバイダー間で標準化されていません。これは主に、一般化できる例がまだ少ないためです。
:::

### AIMessageChunk

チャットモデルでは、レスポンスが生成されると同時に[ストリーミング](/docs/concepts/streaming)するのが一般的です。これにより、ユーザーはレスポンス全体が生成されるまで待つことなく、リアルタイムでレスポンスを確認できます。

これは、チャットモデルの `stream`、`astream`、`astream_events` メソッドから返されます。

例えば、

```python
for chunk in model.stream([HumanMessage("what color is the sky?")]):
    print(chunk)
```

`AIMessageChunk` は `AIMessage` とほぼ同じ構造に従いますが、ツール呼び出しを標準化された方法でストリーミングできるように、異なる [ToolCallChunk](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolCallChunk.html#langchain_core.messages.tool.ToolCallChunk) を使用します。


#### 集約

`AIMessageChunks` は `+` 演算子をサポートしており、複数のチャンクを 1 つの `AIMessage` に結合できます。これは、最終的なレスポンスをユーザーに表示したい場合に便利です。

```python
ai_message = chunk1 + chunk2 + chunk3 + ...
```

### ToolMessage

これは、役割が「ツール」であるメッセージを表し、[ツールの呼び出し](/docs/concepts/tool_calling)の結果が含まれます。`role` と `content` に加えて、このメッセージには以下の要素が含まれます。

- `tool_call_id` フィールド: この結果を生成するために呼び出されたツールの呼び出しIDを伝えます。
- `artifact` フィールド: ツール実行時に追跡に有用だがモデルには送信すべきではない任意のアーティファクトを渡すために使用できます。

詳細については、[ツールの呼び出し](/docs/concepts/tool_calling) を参照してください。

### RemoveMessage

これは、どのロールにも該当しない特別なメッセージタイプです。
[LangGraph](/docs/concepts/architecture#langgraph) でチャット履歴を管理するために使用されます。

`RemoveMessage` の使用方法の詳細については、以下をご覧ください。

* [メモリ概念ガイド](https://langchain-ai.github.io/langgraph/concepts/memory/)
* [メッセージの削除方法](https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/)

### (Legacy) FunctionMessage

これは、OpenAI の従来の関数呼び出し API に対応するレガシー メッセージ タイプです。更新されたツール呼び出し API に対応するには、代わりに `ToolMessage` を使用する必要があります。

## OpenAI Format

### Inputs

チャット モデルは、チャット モデルへの **入力** として OpenAI の形式も受け入れます:

```python
chat_model.invoke([
    {
        "role": "user",
        "content": "Hello, how are you?",
    },
    {
        "role": "assistant",
        "content": "I'm doing well, thank you for asking.",
    },
    {
        "role": "user",
        "content": "Can you tell me a joke?",
    }
])
```

### 出力

現時点では、モデルの出力はLangChainメッセージ形式となります。出力にもOpenAI形式が必要な場合は、出力をOpenAI形式に変換する必要があります。

[convert_to_openai_messages](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.utils.convert_to_openai_messages.html)ユーティリティ関数を使用すると、LangChainメッセージをOpenAI形式に変換できます。
