# なぜLangChainなのか？

Pythonパッケージ「langchain」と企業「LangChain」の目標は、開発者が論理的なアプリケーションを可能な限り簡単に構築できるようにすることです。
LangChainは元々単一のオープンソースパッケージとしてスタートしましたが、企業として、そしてエコシステム全体へと進化しました。
このページでは、LangChainエコシステム全体について説明します。
LangChainエコシステム内のコンポーネントのほとんどは単独で使用できます。そのため、特定のコンポーネントに特に魅力を感じていても、他のコンポーネントが気に入らない場合でも、全く問題ありません。ご自身のユースケースに最適なコンポーネントをお選びください。

## 機能

LangChain が解決を目指す主要なニーズはいくつかあります。

1. **標準化されたコンポーネントインターフェース：** AI アプリケーション向けの [モデル](/docs/integrations/chat/) と [関連コンポーネント](/docs/integrations/vectorstores/) の増加に伴い、開発者は多種多様な API を学習して使用する必要があります。
この多様性により、開発者はアプリケーション構築時にプロバイダーを切り替えたり、コンポーネントを組み合わせたりすることが困難になる可能性があります。
LangChain は主要コンポーネントの標準インターフェースを公開しているため、プロバイダー間の切り替えが容易です。

2. **オーケストレーション：** アプリケーションが複雑になり、複数のコンポーネントとモデルが組み合わされるようになると、[これらの要素を効率的に制御フローに接続し](https://lilianweng.github.io/posts/2023-06-23-agent/)、[多様なタスクを実行](https://www.sequoiacap.com/article/generative-ais-act-o1/) する必要性が高まっています。
[オーケストレーション](https://en.wikipedia.org/wiki/Orchestration_(computing))は、このようなアプリケーションの構築に不可欠です。

3. **可観測性と評価:** アプリケーションが複雑になるにつれて、アプリケーション内で何が起こっているかを把握することがますます困難になります。
さらに、[選択のパラドックス](https://en.wikipedia.org/wiki/Paradox_of_choice)によって開発のペースが制限される可能性があります。
例えば、開発者はプロンプトをどのように設計するか、精度、レイテンシ、コストのバランスが最も取れたLLMはどれか、といった疑問を抱くことがよくあります。
[可観測性](https://en.wikipedia.org/wiki/Observability)と評価は、開発者がアプリケーションを監視し、これらの疑問に自信を持って迅速に答えるのに役立ちます。


## 標準化されたコンポーネントインターフェース

LangChainは、多くのAIアプリケーションの中心となるコンポーネントに共通のインターフェースを提供します。
例えば、すべての[チャットモデル](/docs/concepts/chat_models/)は[BaseChatModel](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html)インターフェースを実装しています。
これは、チャットモデルと対話するための標準的な方法を提供し、[ツール呼び出し](/docs/concepts/tool_calling/)や[構造化出力](/docs/concepts/structured_outputs/)といった、重要でありながら多くの場合プロバイダー固有の機能をサポートします。


### 例：チャットモデル

多くの[モデルプロバイダー](/docs/concepts/chat_models/)は[ツール呼び出し](/docs/concepts/tool_calling/)をサポートしています。これは多くのアプリケーション（例：[エージェント](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)）にとって重要な機能であり、開発者は特定のスキーマに一致するモデルレスポンスをリクエストできます。
各プロバイダーのAPIは異なります。
LangChainの[チャットモデル](/docs/concepts/chat_models/)インターフェースは、[ツール呼び出し](/docs/concepts/tools)をモデルにバインドするための共通の方法を提供します。

```python
# Tool creation
tools = [my_tool]
# Tool binding
model_with_tools = model.bind_tools(tools)
```

同様に、モデルから[構造化出力](/docs/concepts/structured_outputs/)を生成することは、非常に一般的なユースケースです。
プロバイダーは、[JSONモードまたはツール呼び出し](https://platform.openai.com/docs/guides/structured-outputs)など、さまざまなアプローチを、さまざまなAPIでサポートしています。
LangChainの[チャットモデル](/docs/concepts/chat_models/)インターフェースは、`with_structured_output()`メソッドを使用して構造化出力を生成する一般的な方法を提供します。

```python
# Define schema
schema = ...
# Bind schema to model
model_with_structure = model.with_structured_output(schema)
```

### 例: リトリーバー

[RAG](/docs/concepts/rag/) および LLM アプリケーションコンポーネントのコンテキストにおいて、LangChain の [リトリーバー](/docs/concepts/retrievers/) インターフェースは、さまざまな種類のデータサービスやデータベース（例: [ベクターストア](/docs/concepts/vectorstores) やデータベース）に接続するための標準的な方法を提供します。
リトリーバーの基盤となる実装は、接続先のデータストアまたはデータベースの種類によって異なりますが、すべてのリトリーバーは [実行可能インターフェース](/docs/concepts/runnables/) を実装しているため、共通の方法で呼び出すことができます。

```python
documents = my_retriever.invoke("What is the meaning of life?")
```

## オーケストレーション

個々のコンポーネントの標準化は有用ですが、開発者がコンポーネントを*組み合わせて*、より複雑なアプリケーションを構築したいというニーズが増えています。
これが[オーケストレーション](https://en.wikipedia.org/wiki/Orchestration_(computing))の必要性を高めています。
このオーケストレーション層がサポートすべき、LLMアプリケーションに共通する特性がいくつかあります。

* **複雑な制御フロー:** アプリケーションは、サイクル（例: 条件が満たされるまで繰り返し実行されるループ）などの複雑なパターンを必要とします。
* **[永続性](https://langchain-ai.github.io/langgraph/concepts/persistence/):** アプリケーションは[短期および/または長期メモリ](https://langchain-ai.github.io/langgraph/concepts/memory/)を維持する必要があります。
* **[人間参加型](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/):** アプリケーションは、一時停止、確認、編集、特定のステップの承認など、人間による操作を必要とします。

複雑なアプリケーションのコンポーネントをオーケストレーションするための推奨方法は、[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/)です。
LangGraphは、アプリケーションのフローをノードとエッジのセットとして表現することで、開発者に高度な制御を提供するライブラリです。
LangGraph には、[persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/)、[human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)、[memory](https://langchain-ai.github.io/langgraph/concepts/memory/) などの機能が組み込まれています。
特に、[agents](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/) や [multi-agents](https://langchain-ai.github.io/langgraph/concepts/multi_agent/) アプリケーションの構築に適しています。
重要なのは、個々の LangChain コンポーネントを LangGraph ノードとして使用できるだけでなく、LangChain コンポーネントを使用せずに LangGraph を使用することもできることです。

:::info[参考資料]

LangGraph を使って複雑なアプリケーションを構築する方法について詳しくは、無料コース「LangGraph 入門」(https://academy.langchain.com/courses/intro-to-langgraph) をご覧ください。

:::

## 可観測性と評価

AIアプリケーション開発のペースは、選択のパラドックスが存在するため、高品質な評価によって制限されることがよくあります。
開発者は、プロンプトをどのように設計するか、またはどのLLMが精度、レイテンシ、コストのバランスを最も適切に取るか、といった疑問に悩むことがよくあります。
高品質なトレーシングと評価は、こうした疑問に迅速かつ自信を持って答えるのに役立ちます。
[LangSmith](https://docs.smith.langchain.com/)は、AIアプリケーションの可観測性と評価をサポートするプラットフォームです。
詳細については、[評価](https://docs.smith.langchain.com/concepts/evaluation)と[トレーシング](https://docs.smith.langchain.com/concepts/tracing)に関する概念ガイドをご覧ください。

:::info[参考資料]

詳細については、[LangSmith のトレースと評価](https://youtube.com/playlist?list=PLfaIDFEXuae0um8Fj0V4dHG37fGFU8Q5S&feature=shared) に関する動画再生リストをご覧ください。

:::

## 結論

LangChainは、多くのAIアプリケーションの中心となるコンポーネント用の標準インターフェースを提供しており、いくつかの具体的なメリットがあります。
- **プロバイダーの容易な切り替え:** 基盤となるコードを変更することなく、異なるコンポーネントプロバイダーを切り替えられます。
- **高度な機能:** [ストリーミング](/docs/concepts/streaming)や[ツール呼び出し](/docs/concepts/tool_calling/)といった高度な機能のための共通メソッドを提供します。

[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) は、複雑なアプリケーション（[エージェント](/docs/concepts/agents/) など）のオーケストレーションを可能にし、[persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/)、[human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)、[memory](https://langchain-ai.github.io/langgraph/concepts/memory/) などの機能を提供します。

[LangSmith](https://docs.smith.langchain.com/) は、LLM 固有の可観測性とアプリケーションのテストおよび評価のためのフレームワークを提供することで、アプリケーションの反復開発を自信を持って実行することを可能にします。
