{
 "cells": [
  {
   "cell_type": "raw",
   "id": "63ee3f93",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_position: 0\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9316da0d",
   "metadata": {},
   "source": [
    "# チャットモデルとプロンプトテンプレートを使ったシンプルなLLMアプリケーションの構築\n",
    "\n",
    "このクイックスタートでは、LangChainを使ってシンプルなLLMアプリケーションを構築する方法を説明します。このアプリケーションは、英語のテキストを他の言語に翻訳します。これは比較的シンプルなLLMアプリケーションで、LLM呼び出し1回とプロンプトをいくつか実行するだけです。それでも、LangChainを使い始めるには最適な方法です。プロンプトとLLM呼び出しだけで、多くの機能を構築できます。\n",
    "\n",
    "このチュートリアルを読めば、以下の概要を理解できます。\n",
    "\n",
    "- [言語モデル](/docs/concepts/chat_models)の使用\n",
    "\n",
    "- [プロンプトテンプレート](/docs/concepts/prompt_templates)の使用\n",
    "\n",
    "- [LangSmith](https://docs.smith.langchain.com/)を使ったアプリケーションのデバッグとトレース\n",
    "\n",
    "さあ、始めましょう！\n",
    "\n",
    "## セットアップ\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "このチュートリアルやその他のチュートリアルは、[Jupyter Notebook](https://jupyter.org/) で実行するのが最も便利です。インタラクティブな環境でガイドを進めることで、より深く理解することができます。インストール方法については、[こちら](https://jupyter.org/install) をご覧ください。\n",
    "\n",
    "### インストール\n",
    "\n",
    "LangChain をインストールするには、次のコマンドを実行します:\n",
    "\n",
    "<!-- HIDE_IN_NB\n",
    "import Tabs from '@theme/Tabs';\n",
    "import TabItem from '@theme/TabItem';\n",
    "import CodeBlock from \"@theme/CodeBlock\";\n",
    "\n",
    "<Tabs>\n",
    "  <TabItem value=\"pip\" label=\"Pip\" default>\n",
    "    <CodeBlock language=\"bash\">pip install langchain</CodeBlock>\n",
    "  </TabItem>\n",
    "  <TabItem value=\"conda\" label=\"Conda\">\n",
    "    <CodeBlock language=\"bash\">conda install langchain -c conda-forge</CodeBlock>\n",
    "  </TabItem>\n",
    "</Tabs>\n",
    "HIDE_IN_NB -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86874822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "\n",
    "# %pip install langchain\n",
    "# OR\n",
    "# %conda install langchain -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a546a5bc",
   "metadata": {},
   "source": [
    "詳細については、[インストール ガイド](/docs/how_to/installation)をご覧ください。\n",
    "\n",
    "### LangSmith\n",
    "\n",
    "LangChain で構築するアプリケーションの多くは、複数のステップで LLM 呼び出しを複数回実行します。\n",
    "これらのアプリケーションが複雑になるにつれて、チェーンまたはエージェント内で何が起こっているかを正確に検査することが重要になります。\n",
    "これを行うには、[LangSmith](https://smith.langchain.com) を使用するのが最適です。\n",
    "\n",
    "上記のリンクでサインアップしたら、環境変数を設定してトレースのログ記録を開始してください。\n",
    "\n",
    "```shell\n",
    "export LANGSMITH_TRACING=\"true\"\n",
    "export LANGSMITH_API_KEY=\"...\"\n",
    "export LANGSMITH_PROJECT=\"default\" # or any other project name\n",
    "```\n",
    "\n",
    "または、ノートブックの場合は次のように設定できます:\n",
    "\n",
    "```python\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your LangSmith API key (optional): \"\n",
    "    )\n",
    "if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "        prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "    )\n",
    "    if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "        os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5558ca9",
   "metadata": {},
   "source": [
    "## 言語モデルの使用\n",
    "\n",
    "まずは、言語モデルを単体で使う方法を学びましょう。LangChainは、相互に利用可能な様々な言語モデルをサポートしています。特定のモデルの使用開始方法の詳細については、[サポートされている統合](/docs/integrations/chat/)をご覧ください。\n",
    "\n",
    "<!-- HIDE_IN_NB>\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs overrideParams={{openai: {model: \"gpt-4o-mini\"}}} />\n",
    "HIDE_IN_NB -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b41234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5642ff",
   "metadata": {},
   "source": [
    "まずはモデルを直接使ってみましょう。[ChatModels](/docs/concepts/chat_models)はLangChainの[Runnables](/docs/concepts/runnables/)のインスタンスであり、これらを操作するための標準インターフェースを公開しています。モデルを呼び出すには、[messages](/docs/concepts/messages/)のリストを`.invoke`メソッドに渡します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2481f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 20, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-32654a56-627c-40e1-a141-ad9350bbfd3e-0', usage_metadata={'input_tokens': 20, 'output_tokens': 3, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83373db",
   "metadata": {},
   "source": [
    ":::tip\n",
    "\n",
    "LangSmith を有効にしている場合、この実行が LangSmith に記録され、[LangSmith トレース](https://smith.langchain.com/public/88baa0b2-7c1a-4d09-ba30-a47985dde2ea/r) を確認できます。LangSmith トレースは、[トークン](/docs/concepts/tokens/) の使用情報、レイテンシ、[標準モデルパラメータ](/docs/concepts/chat_models/#standard-parameters) (温度など)、その他の情報を報告します。\n",
    "\n",
    ":::\n",
    "\n",
    "ChatModelsは[message](/docs/concepts/messages/)オブジェクトを入力として受け取り、メッセージオブジェクトを出力として生成することに注意してください。メッセージオブジェクトは、テキストコンテンツに加えて、会話における[role](/docs/concepts/messages/#role)を伝え、[tool call](/docs/concepts/tool_calling/)やトークンの使用回数などの重要なデータを保持します。\n",
    "\n",
    "LangChainは、文字列または[OpenAI format](/docs/concepts/messages/#openai-format)によるチャットモデルの入力もサポートしています。以下は同等です。\n",
    "\n",
    "```python\n",
    "model.invoke(\"Hello\")\n",
    "\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "\n",
    "model.invoke([HumanMessage(\"Hello\")])\n",
    "```\n",
    "\n",
    "### ストリーミング\n",
    "\n",
    "チャットモデルは[Runnables](/docs/concepts/runnables/)であるため、非同期およびストリーミング呼び出しモードを含む標準インターフェースを公開しています。これにより、チャットモデルから個々のトークンをストリーミングできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abb0863-bee7-448d-b013-79d8db01e330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|C|iao|!||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5963141-468c-4570-8f2e-5f7cfb6eb3db",
   "metadata": {},
   "source": [
    "チャット モデル出力のストリーミングの詳細については、[このガイド](/docs/how_to/chat_streaming/) を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab8da31",
   "metadata": {},
   "source": [
    "## プロンプトテンプレート\n",
    "\n",
    "現在、メッセージのリストを言語モデルに直接渡しています。このメッセージのリストはどこから来るのでしょうか？通常、これはユーザー入力とアプリケーションロジックの組み合わせから構築されます。このアプリケーションロジックは通常、生のユーザー入力を受け取り、言語モデルに渡す準備が整ったメッセージのリストに変換します。一般的な変換には、システムメッセージの追加や、ユーザー入力に基づいたテンプレートのフォーマット設定などがあります。\n",
    "\n",
    "[プロンプトテンプレート](/docs/concepts/prompt_templates/)は、この変換を支援するために設計されたLangChainの概念です。生のユーザー入力を受け取り、言語モデルに渡す準備が整ったデータ（プロンプト）を返します。\n",
    "\n",
    "ここでプロンプトテンプレートを作成しましょう。2つのユーザー変数を受け取ります。\n",
    "\n",
    "- `language`: テキストを翻訳する言語\n",
    "- `text`: 翻訳するテキスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e73cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e876c2a",
   "metadata": {},
   "source": [
    "`ChatPromptTemplate` は、1 つのテンプレートで複数の [メッセージロール](/docs/concepts/messages/#role) をサポートしていることに注意してください。`language` パラメータはシステムメッセージに、ユーザーの `text` はユーザーメッセージにフォーマットされます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9711ba6",
   "metadata": {},
   "source": [
    "このプロンプトテンプレートへの入力は辞書です。このプロンプトテンプレートを単体で操作して、どのような動作をするか確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781b3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49ba9e",
   "metadata": {},
   "source": [
    "2つのメッセージからなる`ChatPromptValue`が返されていることがわかります。メッセージに直接アクセスしたい場合は、次のようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159b619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e70ee6-f0e0-4ae0-a290-002799ebf828",
   "metadata": {},
   "source": [
    "最後に、フォーマットされたプロンプトでチャット モデルを呼び出すことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a509d8c-e122-4641-b9ee-91bc23aa155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f0bf25-6efb-4853-9a8f-242f2855c84a",
   "metadata": {},
   "source": [
    ":::tip\n",
    "\n",
    "メッセージの「コンテンツ」には、テキストと[コンテンツブロック](/docs/concepts/messages/#aimessage)、そして追加の構造を含めることができます。詳細については、[こちらのガイド](/docs/how_to/output_parser_string/)をご覧ください。\n",
    "\n",
    ":::\n",
    "\n",
    "[LangSmith トレース](https://smith.langchain.com/public/3ccc2d5e-2869-467b-95d6-33a577df99a2/r) を見ると、チャット モデルが受け取るプロンプトのほか、[トークン](/docs/concepts/tokens/) の使用情報、レイテンシ、[標準モデル パラメータ](/docs/concepts/chat_models/#standard-parameters) (温度など)、その他の情報も正確に確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befdb168",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "これで終わりです！このチュートリアルでは、初めてのシンプルなLLMアプリケーションの作成方法を学びました。言語モデルの扱い方、プロンプトテンプレートの作成方法、そしてLangSmithで作成したアプリケーションに優れた可観測性を取り入れる方法も学びました。\n",
    "\n",
    "これは、優れたAIエンジニアになるために学ぶべきことのほんの一部に過ぎません。幸いなことに、他にもたくさんのリソースをご用意しています！\n",
    "\n",
    "LangChainのコアコンセプトについてさらに詳しく知りたい方は、詳細な[概念ガイド](/docs/concepts)をご覧ください。\n",
    "\n",
    "これらの概念についてより具体的なご質問がある場合は、ハウツーガイドの以下のセクションをご覧ください。\n",
    "\n",
    "- [チャットモデル](/docs/how_to/#chat-models)\n",
    "- [プロンプトテンプレート](/docs/how_to/#prompt-templates)\n",
    "\n",
    "LangSmith のドキュメントもご覧ください。\n",
    "\n",
    "- [LangSmith](https://docs.smith.langchain.com)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
